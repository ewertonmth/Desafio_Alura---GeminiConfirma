{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ewertonmth/Desafio_Alura---GeminiConfirma/blob/main/GeminiConfirma3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "faRSL1e2ynM5",
        "outputId": "e1760e2c-fafe-452a-b475-2ba230ccde1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Conectado com sucesso ao Gemini 2.0 Flash!\n",
            "Resposta de teste: ok\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Instalação e configuração do Gemini 2.0 Flash no Google Colab\n",
        "!pip install -q google-generativeai\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Configuração com a sua chave da API\n",
        "genai.configure(api_key=\"AIzaSyA99f2jXmKVCb4akPr9aOW3D0vhMy3-Z0A\")  # ← Substitua por sua chave!\n",
        "\n",
        "# Inicializa o modelo Gemini 2.0 Flash\n",
        "modelo = genai.GenerativeModel(model_name=\"gemini-2.0-flash\")\n",
        "\n",
        "# Teste de conexão com o modelo\n",
        "try:\n",
        "    resposta = modelo.generate_content(\"Diga 'ok' se você está funcionando corretamente.\")\n",
        "    print(\"✅ Conectado com sucesso ao Gemini 2.0 Flash!\")\n",
        "    print(\"Resposta de teste:\", resposta.text)\n",
        "except Exception as e:\n",
        "    print(\"❌ Erro ao conectar à API do Gemini:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "df89fb0d"
      },
      "outputs": [],
      "source": [
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def pesquisa_duckduckgo(query):\n",
        "    \"\"\"\n",
        "    Realiza uma busca no DuckDuckGo (sem necessidade de API).\n",
        "    \"\"\"\n",
        "    url = \"https://html.duckduckgo.com/html/\"\n",
        "    params = {\"q\": query}\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, data=params, headers=headers)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "        links = soup.select(\".result__a\")\n",
        "        resultados = [f\"{link.text}: {link['href']}\" for link in links[:5]]\n",
        "        return \"\\n\".join(resultados) if resultados else \"Nenhum resultado encontrado.\"\n",
        "    except Exception as e:\n",
        "        return f\"Erro na busca DuckDuckGo: {e}\"\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "83a401fa"
      },
      "outputs": [],
      "source": [
        "\n",
        "from datetime import date\n",
        "\n",
        "def verificar_fato_com_gemini(texto_afirmativo, modelo=modelo, buscador=pesquisa_duckduckgo):\n",
        "    \"\"\"\n",
        "    Verifica a veracidade de uma afirmação usando busca no DuckDuckGo e Gemini,\n",
        "    com foco em precisão e contexto temporal.\n",
        "    \"\"\"\n",
        "    data_hoje = date.today().strftime(\"%d de %B de %Y\")\n",
        "    busca = buscador(texto_afirmativo)\n",
        "\n",
        "    prompt = f'''\n",
        "Sua tarefa é verificar se a seguinte afirmação é verdadeira, com base em fatos públicos disponíveis:\n",
        "\n",
        "--- Afirmação ---\n",
        "{texto_afirmativo}\n",
        "\n",
        "--- Contexto Temporal ---\n",
        "Hoje é {data_hoje}. Considere apenas eventos que ocorreram até essa data. Desconsidere notícias antigas ou desatualizadas.\n",
        "\n",
        "--- Resultados da Busca ---\n",
        "{busca}\n",
        "\n",
        "--- Instruções ---\n",
        "1. Avalie se os resultados da busca confirmam a veracidade da afirmação.\n",
        "2. Verifique se há datas ou indícios de atualidade nas fontes apresentadas.\n",
        "3. Considere apenas fontes confiáveis e ignore notícias genéricas ou sem data clara.\n",
        "4. Dê um parecer final: \"Verdadeiro\", \"Falso\" ou \"Não Verificável\".\n",
        "5. Emita uma justificativa com base nos trechos encontrados.\n",
        "6. Analise também se a linguagem da afirmação é neutra, sensacionalista, ou manipulativa.\n",
        "\n",
        "--- Formato da Resposta Esperado ---\n",
        "Resumo\n",
        "Verificação Factual\n",
        "Justificativa\n",
        "Análise de Linguagem\n",
        "Parecer Final\n",
        "'''\n",
        "\n",
        "    try:\n",
        "        resposta = modelo.generate_content(prompt)\n",
        "        return resposta.text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"[Erro ao consultar Gemini: {e}]\"\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RnRC8uLoxjxy"
      },
      "outputs": [],
      "source": [
        "# Função de requisição ao Gemini com temperatura\n",
        "def gemini_request(prompt, model=modelo, temperature=0.7):\n",
        "        \"\"\"\n",
        "        Envia um prompt para o modelo Gemini e retorna a resposta.\n",
        "        Permite configurar a temperatura para ajustar o nível de criatividade.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = model.generate_content(\n",
        "                prompt,\n",
        "                generation_config={\"temperature\": temperature}\n",
        "            )\n",
        "            return response.text.strip()\n",
        "        except Exception as e:\n",
        "            return f\"[Erro na requisição Gemini: {e}]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_IBSmPVBxoTR"
      },
      "outputs": [],
      "source": [
        "# Agente 1: Geração do resumo (temperatura 0.3)\n",
        "def gerar_resumo(texto, model=modelo):\n",
        "    prompt = f\"\"\"\n",
        "    Sua tarefa é resumir o seguinte conteúdo de forma objetiva e clara,\n",
        "    preservando os fatos principais e removendo opiniões ou exageros.\n",
        "\n",
        "    Texto original:\n",
        "    \\\"\\\"\\\"{texto}\\\"\\\"\\\"\n",
        "\n",
        "    Resuma o conteúdo acima em no máximo 5 linhas:\n",
        "    \"\"\"\n",
        "    return gemini_request(prompt, model=model, temperature=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GtrwQZRrxqgB"
      },
      "outputs": [],
      "source": [
        "def verificar_fatos(resumo, model=modelo):\n",
        "        # 1. Realiza a busca no Google usando a sua função externa\n",
        "        resultados_busca = pesquisa_duckduckgo(resumo) # Usa sua função google_search e GOOGLE_CSE_ID\n",
        "\n",
        "        # 2. Monta o prompt INCLUINDO os resultados da busca\n",
        "        prompt = f\"\"\"\n",
        "        Você é um verificador de fatos. Analise o seguinte resumo de uma notícia e diga se ele apresenta informações\n",
        "        verdadeiras, falsas ou duvidosas com base no conhecimento geral, nas fontes confiáveis listadas abaixo e em informações públicas.\n",
        "\n",
        "        Resumo da notícia:\n",
        "        \\\"\\\"\\\"{resumo}\\\"\\\"\\\"\n",
        "\n",
        "        Resultados da busca no Google:\n",
        "        {resultados_busca} # Os resultados da busca são adicionados aqui\n",
        "\n",
        "        Diga se o conteúdo parece confiável, falso ou impreciso. Justifique sua análise de forma objetiva.\n",
        "        \"\"\"\n",
        "        # 3. Envia o prompt COMPLETO (com os resultados da busca) para o Gemini\n",
        "        return gemini_request(prompt, model=model, temperature=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2jRzhS4Zxsex"
      },
      "outputs": [],
      "source": [
        "# Agente 3: Análise de linguagem manipulativa (temperatura 0.7)\n",
        "def analisar_linguagem(texto, model=modelo):\n",
        "    prompt = f\"\"\"\n",
        "    Analise o seguinte texto e identifique se ele contém linguagem manipulativa, sensacionalista ou tendenciosa,\n",
        "    como apelos emocionais, exageros ou tentativa de influenciar o leitor.\n",
        "\n",
        "    Texto:\n",
        "    \\\"\\\"\\\"{texto}\\\"\\\"\\\"\n",
        "\n",
        "    Indique os principais pontos de manipulação encontrados e explique brevemente.\n",
        "    \"\"\"\n",
        "    return gemini_request(prompt, model=model, temperature=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "65IgOxO7xuOg"
      },
      "outputs": [],
      "source": [
        "# Agente 4: Geração do parecer final (temperatura 0.8)\n",
        "def gerar_parecer_final(resumo, verificacao, linguagem, model=modelo):\n",
        "    prompt = f\"\"\"\n",
        "    Com base nas informações a seguir, faça um parecer final sobre a confiabilidade da notícia,\n",
        "    usando linguagem clara e objetiva.\n",
        "\n",
        "    Resumo da notícia:\n",
        "    \\\"\\\"\\\"{resumo}\\\"\\\"\\\"\n",
        "\n",
        "    Verificação factual:\n",
        "    \\\"\\\"\\\"{verificacao}\\\"\\\"\\\"\n",
        "\n",
        "    Análise de linguagem:\n",
        "    \\\"\\\"\\\"{linguagem}\\\"\\\"\\\"\n",
        "\n",
        "    Parecer final:\n",
        "    \"\"\"\n",
        "    return gemini_request(prompt, model=model, temperature=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Nvi8WU5oxwEx"
      },
      "outputs": [],
      "source": [
        "# Função que integra o fluxo completo\n",
        "def analisar_texto_completo(texto):\n",
        "    resumo = gerar_resumo(texto)\n",
        "    verificacao = verificar_fatos(resumo)\n",
        "    linguagem = analisar_linguagem(texto)\n",
        "    parecer = gerar_parecer_final(resumo, verificacao, linguagem)\n",
        "\n",
        "    return {\n",
        "        \"Resumo\": resumo,\n",
        "        \"Verificação Factual\": verificacao,\n",
        "        \"Análise de Linguagem\": linguagem,\n",
        "        \"Parecer Final\": parecer\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "CWM2FSH6xxta",
        "outputId": "064a8311-8e9e-4df4-eb7b-db506db276df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Digite o texto(ou link) da notícia ou conteúdo para análise:\n",
            "Palmeiras perde jogo contra o flamengo por 2 x 0 no último jogo deles\n",
            "\n",
            "--- Resumo ---\n",
            "O Palmeiras perdeu para o Flamengo por 2 a 0 em sua última partida.\n",
            "\n",
            "--- Verificação Factual ---\n",
            "Com base nas fontes fornecidas, a afirmação de que \"O Palmeiras perdeu para o Flamengo por 2 a 0 em sua última partida\" é **verdadeira**.\n",
            "\n",
            "**Justificativa:**\n",
            "\n",
            "*   Várias fontes noticiam a derrota do Palmeiras para o Flamengo por 2 a 0.\n",
            "*   O link da Globo Esporte (\"Palmeiras 0 x 2 Flamengo | Campeonato Brasileiro: melhores momentos\") confirma o placar.\n",
            "*   Outras fontes, como Jovem Pan e Gazeta Esportiva, também relatam a derrota do Palmeiras por 2 a 0 para o Flamengo.\n",
            "\n",
            "--- Análise de Linguagem ---\n",
            "O texto \"Palmeiras perde jogo contra o Flamengo por 2 x 0 no último jogo deles\" é **factual e direto**, sem apresentar elementos de manipulação, sensacionalismo ou tendenciosidade.\n",
            "\n",
            "**Análise:**\n",
            "\n",
            "*   **Ausência de Apelos Emocionais:** O texto simplesmente relata o resultado de uma partida, sem usar palavras ou frases que tentem provocar emoções específicas no leitor (como tristeza, raiva ou indignação).\n",
            "\n",
            "*   **Ausência de Exageros:** A informação é apresentada de forma objetiva, sem amplificar a importância da derrota ou usar adjetivos superlativos.\n",
            "\n",
            "*   **Ausência de Tendência:** Não há indicação de parcialidade ou tentativa de influenciar a opinião do leitor sobre o Palmeiras, o Flamengo ou o resultado da partida. O texto não sugere culpados, não minimiza ou maximiza o resultado e não faz juízos de valor.\n",
            "\n",
            "**Em resumo:** O texto é um relato simples de um evento esportivo, sem intenção aparente de manipular a percepção do leitor.\n",
            "\n",
            "--- Parecer Final ---\n",
            "**Parecer Final: Altamente Confiável.**\n",
            "\n",
            "A notícia que afirma que \"O Palmeiras perdeu para o Flamengo por 2 a 0 em sua última partida\" é considerada altamente confiável. A verificação factual demonstra a veracidade da informação, confirmada por diversas fontes. A análise da linguagem revela que o texto é factual, direto e isento de elementos de manipulação, sensacionalismo ou tendenciosidade.\n"
          ]
        }
      ],
      "source": [
        "# Função que integra o fluxo completo\n",
        "def analisar_texto_completo(texto):\n",
        "    resumo = gerar_resumo(texto)\n",
        "    verificacao = verificar_fatos(resumo)\n",
        "    linguagem = analisar_linguagem(texto)\n",
        "    parecer = gerar_parecer_final(resumo, verificacao, linguagem)\n",
        "\n",
        "    return {\n",
        "        \"Resumo\": resumo,\n",
        "        \"Verificação Factual\": verificacao,\n",
        "        \"Análise de Linguagem\": linguagem,\n",
        "        \"Parecer Final\": parecer\n",
        "    }\n",
        "\n",
        "# Entrada do usuário\n",
        "texto_teste = input(\"Digite o texto(ou link) da notícia ou conteúdo para análise:\\n\")\n",
        "\n",
        "# Executa a análise\n",
        "resultado = analisar_texto_completo(texto_teste)\n",
        "\n",
        "# Exibe o resultado formatado\n",
        "for etapa, texto in resultado.items():\n",
        "    print(f\"\\n--- {etapa} ---\\n{texto}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}